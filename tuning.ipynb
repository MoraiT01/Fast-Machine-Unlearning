{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Finetuning\n",
    "\n",
    "We want to find the right parameters for the Generator Network.\n",
    "\n",
    "By using the best values for the following parameters:\n",
    "\n",
    "- Number of Epochs (meaning `num_epochs` and `num_steps`)\n",
    "- Learning Rate\n",
    "- Batch Size\n",
    "- Number of Noise Batches\n",
    "- Number of Layers\n",
    "- Regularization term\n",
    "- Number of Neurons for each Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.fyemu_tunable import main, evaluate\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import optuna\n",
    "import random\n",
    "from typing import Dict\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from src.metrics import kl_divergence_between_models\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_dict(path: str=\"data/new/models\") -> Dict[str, torch.nn.Module]:\n",
    "    de = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(num_classes = 10).to(de)\n",
    "    \n",
    "    # load all the models\n",
    "    md = {}\n",
    "    for list in os.listdir(path):\n",
    "        \n",
    "        model.load_state_dict(torch.load(f=os.path.join(path, list), map_location=DEVICE, weights_only=True))\n",
    "        model.eval()\n",
    "        md[len(md)] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this little tutorial, to see how we handle the optimization using save states:\n",
    "\n",
    "https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/001_rdb.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 19:35:45,406] Using an existing study with name 'GeneratorOpti2' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an existing study with name 'GeneratorOpti2' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import optuna\n",
    "\n",
    "# Add stream handler of stdout to show the messages\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"GeneratorOpti2\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "if os.path.exists(\"sampler2.pkl\"):\n",
    "    restored_sampler = pickle.load(open(\"sampler2.pkl\", \"rb\"))\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, sampler=restored_sampler)\n",
    "else:\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 19:44:13,660] Trial 36 finished with value: 2.475285187363625 and parameters: {'opt_Epochs': 2, 'opt_Steps': 9, 'opt_Learning_Rate': 0.03828025424426709, 'opt_Batch_Size': 244, 'opt_Number_of_Noise_Batches': 7, 'opt_Regularization_term': 0.23029181440784674, 'opt_Noise_Dim': 183, 'n_layers': 3}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 finished with value: 2.475285187363625 and parameters: {'opt_Epochs': 2, 'opt_Steps': 9, 'opt_Learning_Rate': 0.03828025424426709, 'opt_Batch_Size': 244, 'opt_Number_of_Noise_Batches': 7, 'opt_Regularization_term': 0.23029181440784674, 'opt_Noise_Dim': 183, 'n_layers': 3}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 19:55:19,597] Trial 37 finished with value: 2.4421422153711325 and parameters: {'opt_Epochs': 3, 'opt_Steps': 13, 'opt_Learning_Rate': 0.061887100278658784, 'opt_Batch_Size': 233, 'opt_Number_of_Noise_Batches': 6, 'opt_Regularization_term': 0.25923289343932054, 'opt_Noise_Dim': 96, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 finished with value: 2.4421422153711325 and parameters: {'opt_Epochs': 3, 'opt_Steps': 13, 'opt_Learning_Rate': 0.061887100278658784, 'opt_Batch_Size': 233, 'opt_Number_of_Noise_Batches': 6, 'opt_Regularization_term': 0.25923289343932054, 'opt_Noise_Dim': 96, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 19:59:49,937] Trial 38 finished with value: 2.5746352642774584 and parameters: {'opt_Epochs': 1, 'opt_Steps': 8, 'opt_Learning_Rate': 0.024695075675066146, 'opt_Batch_Size': 159, 'opt_Number_of_Noise_Batches': 5, 'opt_Regularization_term': 0.28272537374548085, 'opt_Noise_Dim': 160, 'n_layers': 2}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 finished with value: 2.5746352642774584 and parameters: {'opt_Epochs': 1, 'opt_Steps': 8, 'opt_Learning_Rate': 0.024695075675066146, 'opt_Batch_Size': 159, 'opt_Number_of_Noise_Batches': 5, 'opt_Regularization_term': 0.28272537374548085, 'opt_Noise_Dim': 160, 'n_layers': 2}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:08:29,698] Trial 39 finished with value: 2.4010619416832917 and parameters: {'opt_Epochs': 2, 'opt_Steps': 10, 'opt_Learning_Rate': 0.05965992069552965, 'opt_Batch_Size': 203, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.20922097005021456, 'opt_Noise_Dim': 223, 'n_layers': 7}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 finished with value: 2.4010619416832917 and parameters: {'opt_Epochs': 2, 'opt_Steps': 10, 'opt_Learning_Rate': 0.05965992069552965, 'opt_Batch_Size': 203, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.20922097005021456, 'opt_Noise_Dim': 223, 'n_layers': 7}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:21:42,092] Trial 40 finished with value: 2.5436935648322114 and parameters: {'opt_Epochs': 4, 'opt_Steps': 13, 'opt_Learning_Rate': 0.01001910274694122, 'opt_Batch_Size': 282, 'opt_Number_of_Noise_Batches': 8, 'opt_Regularization_term': 0.22134418791927576, 'opt_Noise_Dim': 103, 'n_layers': 2}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 finished with value: 2.5436935648322114 and parameters: {'opt_Epochs': 4, 'opt_Steps': 13, 'opt_Learning_Rate': 0.01001910274694122, 'opt_Batch_Size': 282, 'opt_Number_of_Noise_Batches': 8, 'opt_Regularization_term': 0.22134418791927576, 'opt_Noise_Dim': 103, 'n_layers': 2}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:34:28,089] Trial 41 finished with value: 2.5541708528995515 and parameters: {'opt_Epochs': 5, 'opt_Steps': 12, 'opt_Learning_Rate': 0.10283287299168228, 'opt_Batch_Size': 200, 'opt_Number_of_Noise_Batches': 6, 'opt_Regularization_term': 0.24277132466528273, 'opt_Noise_Dim': 19, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 finished with value: 2.5541708528995515 and parameters: {'opt_Epochs': 5, 'opt_Steps': 12, 'opt_Learning_Rate': 0.10283287299168228, 'opt_Batch_Size': 200, 'opt_Number_of_Noise_Batches': 6, 'opt_Regularization_term': 0.24277132466528273, 'opt_Noise_Dim': 19, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:40:05,473] Trial 42 finished with value: 2.6224380791187287 and parameters: {'opt_Epochs': 7, 'opt_Steps': 5, 'opt_Learning_Rate': 0.02999365754281076, 'opt_Batch_Size': 101, 'opt_Number_of_Noise_Batches': 4, 'opt_Regularization_term': 0.257221539577231, 'opt_Noise_Dim': 394, 'n_layers': 3}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 finished with value: 2.6224380791187287 and parameters: {'opt_Epochs': 7, 'opt_Steps': 5, 'opt_Learning_Rate': 0.02999365754281076, 'opt_Batch_Size': 101, 'opt_Number_of_Noise_Batches': 4, 'opt_Regularization_term': 0.257221539577231, 'opt_Noise_Dim': 394, 'n_layers': 3}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:47:09,522] Trial 43 finished with value: 2.33573172390461 and parameters: {'opt_Epochs': 3, 'opt_Steps': 7, 'opt_Learning_Rate': 0.052655277383312576, 'opt_Batch_Size': 178, 'opt_Number_of_Noise_Batches': 7, 'opt_Regularization_term': 0.28726073532728874, 'opt_Noise_Dim': 463, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 finished with value: 2.33573172390461 and parameters: {'opt_Epochs': 3, 'opt_Steps': 7, 'opt_Learning_Rate': 0.052655277383312576, 'opt_Batch_Size': 178, 'opt_Number_of_Noise_Batches': 7, 'opt_Regularization_term': 0.28726073532728874, 'opt_Noise_Dim': 463, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 20:55:31,797] Trial 44 finished with value: 2.3632215186953545 and parameters: {'opt_Epochs': 3, 'opt_Steps': 7, 'opt_Learning_Rate': 0.08706531911307087, 'opt_Batch_Size': 153, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2868481802280207, 'opt_Noise_Dim': 452, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 finished with value: 2.3632215186953545 and parameters: {'opt_Epochs': 3, 'opt_Steps': 7, 'opt_Learning_Rate': 0.08706531911307087, 'opt_Batch_Size': 153, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2868481802280207, 'opt_Noise_Dim': 452, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:03:06,076] Trial 45 finished with value: 2.5314333558082582 and parameters: {'opt_Epochs': 3, 'opt_Steps': 6, 'opt_Learning_Rate': 0.07321977746852842, 'opt_Batch_Size': 155, 'opt_Number_of_Noise_Batches': 10, 'opt_Regularization_term': 0.2876249360608091, 'opt_Noise_Dim': 455, 'n_layers': 5}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 finished with value: 2.5314333558082582 and parameters: {'opt_Epochs': 3, 'opt_Steps': 6, 'opt_Learning_Rate': 0.07321977746852842, 'opt_Batch_Size': 155, 'opt_Number_of_Noise_Batches': 10, 'opt_Regularization_term': 0.2876249360608091, 'opt_Noise_Dim': 455, 'n_layers': 5}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:13:11,837] Trial 46 finished with value: 2.8321766793727874 and parameters: {'opt_Epochs': 3, 'opt_Steps': 8, 'opt_Learning_Rate': 0.08406480121761428, 'opt_Batch_Size': 185, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2990682481895076, 'opt_Noise_Dim': 469, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 finished with value: 2.8321766793727874 and parameters: {'opt_Epochs': 3, 'opt_Steps': 8, 'opt_Learning_Rate': 0.08406480121761428, 'opt_Batch_Size': 185, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2990682481895076, 'opt_Noise_Dim': 469, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:20:24,940] Trial 47 finished with value: 2.894526633620262 and parameters: {'opt_Epochs': 6, 'opt_Steps': 7, 'opt_Learning_Rate': 0.05305614282115011, 'opt_Batch_Size': 45, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2680580606048082, 'opt_Noise_Dim': 512, 'n_layers': 7}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 finished with value: 2.894526633620262 and parameters: {'opt_Epochs': 6, 'opt_Steps': 7, 'opt_Learning_Rate': 0.05305614282115011, 'opt_Batch_Size': 45, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.2680580606048082, 'opt_Noise_Dim': 512, 'n_layers': 7}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:25:29,493] Trial 48 finished with value: 2.6553657263517376 and parameters: {'opt_Epochs': 1, 'opt_Steps': 4, 'opt_Learning_Rate': 0.1468701433498582, 'opt_Batch_Size': 140, 'opt_Number_of_Noise_Batches': 8, 'opt_Regularization_term': 0.281348249846726, 'opt_Noise_Dim': 425, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 finished with value: 2.6553657263517376 and parameters: {'opt_Epochs': 1, 'opt_Steps': 4, 'opt_Learning_Rate': 0.1468701433498582, 'opt_Batch_Size': 140, 'opt_Number_of_Noise_Batches': 8, 'opt_Regularization_term': 0.281348249846726, 'opt_Noise_Dim': 425, 'n_layers': 4}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:34:05,628] Trial 49 finished with value: 2.4068859398365023 and parameters: {'opt_Epochs': 3, 'opt_Steps': 6, 'opt_Learning_Rate': 0.1782616289648098, 'opt_Batch_Size': 179, 'opt_Number_of_Noise_Batches': 10, 'opt_Regularization_term': 0.0587673532602592, 'opt_Noise_Dim': 414, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 finished with value: 2.4068859398365023 and parameters: {'opt_Epochs': 3, 'opt_Steps': 6, 'opt_Learning_Rate': 0.1782616289648098, 'opt_Batch_Size': 179, 'opt_Number_of_Noise_Batches': 10, 'opt_Regularization_term': 0.0587673532602592, 'opt_Noise_Dim': 414, 'n_layers': 6}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 21:39:57,725] Trial 50 finished with value: 2.4679413437843327 and parameters: {'opt_Epochs': 4, 'opt_Steps': 2, 'opt_Learning_Rate': 0.02697893912930327, 'opt_Batch_Size': 106, 'opt_Number_of_Noise_Batches': 4, 'opt_Regularization_term': 0.015293660285069816, 'opt_Noise_Dim': 484, 'n_layers': 5}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 finished with value: 2.4679413437843327 and parameters: {'opt_Epochs': 4, 'opt_Steps': 2, 'opt_Learning_Rate': 0.02697893912930327, 'opt_Batch_Size': 106, 'opt_Number_of_Noise_Batches': 4, 'opt_Regularization_term': 0.015293660285069816, 'opt_Noise_Dim': 484, 'n_layers': 5}. Best is trial 17 with value: 2.2544206410646437.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    opt_Epochs = trial.suggest_int('opt_Epochs', 1, 10)\n",
    "    opt_Steps = trial.suggest_int('opt_Steps', 1, 20)\n",
    "    opt_Learning_Rate = trial.suggest_float('opt_Learning_Rate', 0.01, 0.3)\n",
    "    opt_Batch_Size = trial.suggest_int('opt_Batch_Size', 32, 512)\n",
    "    opt_Number_of_Noise_Batches = trial.suggest_int('opt_Number_of_Noise_Batches', 1, 10)\n",
    "    opt_Regularization_term = trial.suggest_float('opt_Regularization_term', 0.01, 0.3)\n",
    "    opt_Noise_Dim = trial.suggest_int('opt_Noise_Dim', 1, 512)\n",
    "\n",
    "    # print(f\"Epochs: {opt_Epochs} |\\nSteps: {opt_Steps} |\\nLearning Rate: {opt_Learning_Rate} |\\nBatch Size: {opt_Batch_Size} |\\nNoise Batches: {opt_Number_of_Noise_Batches} |\\nRegularization Term: {opt_Regularization_term} |\\nNoise Dim: {opt_Noise_Dim}\")\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 8)\n",
    "\n",
    "    Layers = [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,]\n",
    "    Layers = Layers[:n_layers]\n",
    "    # print(\"Layers: \", Layers)\n",
    "\n",
    "    mod = main(\n",
    "        t_Epochs = opt_Epochs,\n",
    "        t_Steps= opt_Steps,\n",
    "        t_Learning_Rate = opt_Learning_Rate,\n",
    "        t_Batch_Size = opt_Batch_Size,\n",
    "        t_Number_of_Noise_Batches = opt_Number_of_Noise_Batches,\n",
    "        t_Regularization_term = opt_Regularization_term,\n",
    "        t_Layers = Layers,\n",
    "        t_Noise_Dim = opt_Noise_Dim,\n",
    "        new_baseline=False,\n",
    "        logs=False,\n",
    "        model_eval_logs=False,\n",
    "    )\n",
    "    \n",
    "    data_dir = f'data{os.sep}cifar10'\n",
    "\n",
    "    transform_test = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    valid_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "    valid_dl = DataLoader(valid_ds, 256,)\n",
    "\n",
    "    exact = resnet18(num_classes = 10)\n",
    "    n = random.randint(0, len(os.listdir(\"data/retrain/models\"))-1)\n",
    "    exact.load_state_dict(torch.load(f\"data/retrain/models/ResNET18_CIFAR10_RETRAIN_CLASSES_{n}.pt\", map_location=DEVICE, weights_only=True))\n",
    "    div = kl_divergence_between_models(\n",
    "        model1 = exact,\n",
    "        model2 = mod,\n",
    "        data_loader = valid_dl,\n",
    "    )\n",
    "\n",
    "    return div\n",
    "\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the sampler with pickle to be loaded later.\n",
    "with open(\"sampler2.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study.sampler, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opt_Epochs': 1,\n",
       " 'opt_Steps': 8,\n",
       " 'opt_Learning_Rate': 0.011837483759601058,\n",
       " 'opt_Batch_Size': 278,\n",
       " 'opt_Number_of_Noise_Batches': 1,\n",
       " 'opt_Regularization_term': 0.27394634876638047,\n",
       " 'opt_Noise_Dim': 308,\n",
       " 'n_layers': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_n_layers</th>\n",
       "      <th>params_opt_Batch_Size</th>\n",
       "      <th>params_opt_Epochs</th>\n",
       "      <th>params_opt_Learning_Rate</th>\n",
       "      <th>params_opt_Noise_Dim</th>\n",
       "      <th>params_opt_Number_of_Noise_Batches</th>\n",
       "      <th>params_opt_Regularization_term</th>\n",
       "      <th>params_opt_Steps</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2.254421</td>\n",
       "      <td>2025-01-17 22:19:20.289658</td>\n",
       "      <td>2025-01-17 22:23:22.093268</td>\n",
       "      <td>0 days 00:04:01.803610</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273946</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.305901</td>\n",
       "      <td>2025-01-17 12:31:05.669089</td>\n",
       "      <td>2025-01-17 12:31:37.217590</td>\n",
       "      <td>0 days 00:00:31.548501</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>10</td>\n",
       "      <td>0.206408</td>\n",
       "      <td>426</td>\n",
       "      <td>5</td>\n",
       "      <td>0.180352</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2.335732</td>\n",
       "      <td>2025-01-18 20:40:05.484886</td>\n",
       "      <td>2025-01-18 20:47:09.470360</td>\n",
       "      <td>0 days 00:07:03.985474</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>0.052655</td>\n",
       "      <td>463</td>\n",
       "      <td>7</td>\n",
       "      <td>0.287261</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2.350066</td>\n",
       "      <td>2025-01-17 23:01:46.201408</td>\n",
       "      <td>2025-01-17 23:07:35.174347</td>\n",
       "      <td>0 days 00:05:48.972939</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>146</td>\n",
       "      <td>6</td>\n",
       "      <td>0.255710</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2.363222</td>\n",
       "      <td>2025-01-18 20:47:09.542484</td>\n",
       "      <td>2025-01-18 20:55:31.755392</td>\n",
       "      <td>0 days 00:08:22.212908</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087065</td>\n",
       "      <td>452</td>\n",
       "      <td>9</td>\n",
       "      <td>0.286848</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2.369770</td>\n",
       "      <td>2025-01-18 08:53:15.729876</td>\n",
       "      <td>2025-01-18 09:01:29.863646</td>\n",
       "      <td>0 days 00:08:14.133770</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039383</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>0.234037</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>2.401062</td>\n",
       "      <td>2025-01-18 19:59:49.947392</td>\n",
       "      <td>2025-01-18 20:08:29.672904</td>\n",
       "      <td>0 days 00:08:39.725512</td>\n",
       "      <td>7</td>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059660</td>\n",
       "      <td>223</td>\n",
       "      <td>9</td>\n",
       "      <td>0.209221</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2.406886</td>\n",
       "      <td>2025-01-18 21:25:29.519228</td>\n",
       "      <td>2025-01-18 21:34:05.582655</td>\n",
       "      <td>0 days 00:08:36.063427</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>414</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2.424112</td>\n",
       "      <td>2025-01-17 22:15:48.429246</td>\n",
       "      <td>2025-01-17 22:19:20.247258</td>\n",
       "      <td>0 days 00:03:31.818012</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>316</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230344</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2.442142</td>\n",
       "      <td>2025-01-18 19:44:13.672352</td>\n",
       "      <td>2025-01-18 19:55:19.560128</td>\n",
       "      <td>0 days 00:11:05.887776</td>\n",
       "      <td>4</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>0.061887</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>0.259233</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "17      17  2.254421 2025-01-17 22:19:20.289658 2025-01-17 22:23:22.093268   \n",
       "5        5  2.305901 2025-01-17 12:31:05.669089 2025-01-17 12:31:37.217590   \n",
       "43      43  2.335732 2025-01-18 20:40:05.484886 2025-01-18 20:47:09.470360   \n",
       "21      21  2.350066 2025-01-17 23:01:46.201408 2025-01-17 23:07:35.174347   \n",
       "44      44  2.363222 2025-01-18 20:47:09.542484 2025-01-18 20:55:31.755392   \n",
       "26      26  2.369770 2025-01-18 08:53:15.729876 2025-01-18 09:01:29.863646   \n",
       "39      39  2.401062 2025-01-18 19:59:49.947392 2025-01-18 20:08:29.672904   \n",
       "49      49  2.406886 2025-01-18 21:25:29.519228 2025-01-18 21:34:05.582655   \n",
       "16      16  2.424112 2025-01-17 22:15:48.429246 2025-01-17 22:19:20.247258   \n",
       "37      37  2.442142 2025-01-18 19:44:13.672352 2025-01-18 19:55:19.560128   \n",
       "\n",
       "                 duration  params_n_layers  params_opt_Batch_Size  \\\n",
       "17 0 days 00:04:01.803610                2                    278   \n",
       "5  0 days 00:00:31.548501                3                    186   \n",
       "43 0 days 00:07:03.985474                4                    178   \n",
       "21 0 days 00:05:48.972939                3                    234   \n",
       "44 0 days 00:08:22.212908                6                    153   \n",
       "26 0 days 00:08:14.133770                3                    239   \n",
       "39 0 days 00:08:39.725512                7                    203   \n",
       "49 0 days 00:08:36.063427                6                    179   \n",
       "16 0 days 00:03:31.818012                3                    170   \n",
       "37 0 days 00:11:05.887776                4                    233   \n",
       "\n",
       "    params_opt_Epochs  params_opt_Learning_Rate  params_opt_Noise_Dim  \\\n",
       "17                  1                  0.011837                   308   \n",
       "5                  10                  0.206408                   426   \n",
       "43                  3                  0.052655                   463   \n",
       "21                  2                  0.016953                   146   \n",
       "44                  3                  0.087065                   452   \n",
       "26                  2                  0.039383                   144   \n",
       "39                  2                  0.059660                   223   \n",
       "49                  3                  0.178262                   414   \n",
       "16                  1                  0.013416                   316   \n",
       "37                  3                  0.061887                    96   \n",
       "\n",
       "    params_opt_Number_of_Noise_Batches  params_opt_Regularization_term  \\\n",
       "17                                   1                        0.273946   \n",
       "5                                    5                        0.180352   \n",
       "43                                   7                        0.287261   \n",
       "21                                   6                        0.255710   \n",
       "44                                   9                        0.286848   \n",
       "26                                   7                        0.234037   \n",
       "39                                   9                        0.209221   \n",
       "49                                  10                        0.058767   \n",
       "16                                   2                        0.230344   \n",
       "37                                   6                        0.259233   \n",
       "\n",
       "    params_opt_Steps     state  \n",
       "17                 8  COMPLETE  \n",
       "5                  3  COMPLETE  \n",
       "43                 7  COMPLETE  \n",
       "21                 8  COMPLETE  \n",
       "44                 7  COMPLETE  \n",
       "26                11  COMPLETE  \n",
       "39                10  COMPLETE  \n",
       "49                 6  COMPLETE  \n",
       "16                 6  COMPLETE  \n",
       "37                13  COMPLETE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_df = study.trials_dataframe()\n",
    "best10_df = trials_df.sort_values(\"value\").head(10)\n",
    "best10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value 2.818575150200299\n",
      "Number of Layers 4.5 \n",
      "Batch Size for Training 270.5 \n",
      "Epochs for Noise Training 6.0 \n",
      "LR for Noise Training 0.14101033415351125 \n",
      "Noise Dim of Generator 209.1\n",
      "Number of Noise Batches Used 5.5 \n",
      "Regularization Term 0.09653515835859165 \n",
      "Learning Steps for Noise Training 12.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Value {float(best10_df[\"value\"].mean())}\")\n",
    "print(f\"Number of Layers {float(best10_df[\"params_n_layers\"].mean())} \")\n",
    "print(f\"Batch Size for Training {float(best10_df[\"params_opt_Batch_Size\"].mean())} \")\n",
    "print(f\"Epochs for Noise Training {float(best10_df[\"params_opt_Epochs\"].mean())} \")\n",
    "print(f\"LR for Noise Training {float(best10_df[\"params_opt_Learning_Rate\"].mean())} \")\n",
    "print(f\"Noise Dim of Generator {float(best10_df[\"params_opt_Noise_Dim\"].mean())}\")\n",
    "print(f\"Number of Noise Batches Used {float(best10_df[\"params_opt_Number_of_Noise_Batches\"].mean())} \")\n",
    "print(f\"Regularization Term {float(best10_df[\"params_opt_Regularization_term\"].mean())} \")\n",
    "print(f\"Learning Steps for Noise Training {float(best10_df[\"params_opt_Steps\"].mean())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^This will represent the values used as default^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Standard Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n0 = 5000\n",
    "# n2 = 5000\n",
    "# batch_size = 128\n",
    "\n",
    "# standard_model, standard_history = main(\n",
    "#     t_Epochs = 5,\n",
    "#     t_Steps= int((n0 + n2)/(2 * batch_size)), # The Idea is to have the same amount of updates as their are samples to unlearn\n",
    "#     t_Learning_Rate = 0.1,\n",
    "#     t_Batch_Size = batch_size,\n",
    "#     t_Number_of_Noise_Batches = 10,\n",
    "#     t_Regularization_term = 0.1,\n",
    "#     t_Layers = [1000],\n",
    "#     t_Noise_Dim = 100,\n",
    "#     new_baseline=True,\n",
    "#     logs=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_ms = load_models_dict(path=\"data/all/models\")\n",
    "\n",
    "exact_ms = load_models_dict(path=\"data/retrain/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import kl_divergence_between_models\n",
    "import os\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "batch_size = 256\n",
    "data_dir = f'data{os.sep}cifar10'\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "valid_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, shuffle=False)\n",
    "\n",
    "kl_divergence_between_models(model1 = train_ms[0], model2 = train_ms[0], data_loader = valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_between_models(model1=exact_ms[0], model2=exact_ms[0], data_loader=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_between_models(model1=train_ms[0], model2=exact_ms[0], data_loader=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_between_models(model1=exact_ms[0], model2=train_ms[0], data_loader=valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
