{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Finetuning\n",
    "\n",
    "We want to find the right parameters for the Generator Network.\n",
    "\n",
    "By using the best values for the following parameters:\n",
    "\n",
    "- Number of Epochs (meaning `num_epochs` and `num_steps`)\n",
    "- Learning Rate\n",
    "- Batch Size\n",
    "- Number of Noise Batches\n",
    "- Number of Layers\n",
    "- Regularization term\n",
    "- Number of Neurons for each Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fyemu_tunable import main\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import optuna\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from src.metrics import kl_divergence_between_models\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "\n",
    "    global valid_dl\n",
    "\n",
    "    opt_Epochs = trial.suggest_int('opt_Epochs', 1, 10)\n",
    "    opt_Steps = trial.suggest_int('opt_Steps', 1, 10)\n",
    "    opt_Learning_Rate = trial.suggest_float('opt_Learning_Rate', 0.01, 0.3)\n",
    "    opt_Batch_Size = trial.suggest_int('opt_Batch_Size', 32, 256)\n",
    "    opt_Number_of_Noise_Batches = trial.suggest_int('opt_Number_of_Noise_Batches', 1, 10)\n",
    "    opt_Regularization_term = trial.suggest_float('opt_Regularization_term', 0.01, 0.3)\n",
    "    opt_Noise_Dim = trial.suggest_int('opt_Noise_Dim', 1, 512)\n",
    "\n",
    "    print(f\"Epochs: {opt_Epochs} |\\nSteps: {opt_Steps} |\\nLearning Rate: {opt_Learning_Rate} |\\nBatch Size: {opt_Batch_Size} |\\nNoise Batches: {opt_Number_of_Noise_Batches} |\\nRegularization Term: {opt_Regularization_term} |\\nNoise Dim: {opt_Noise_Dim}\")\n",
    "\n",
    "    l1 = trial.suggest_int('l1', 32, 1024)\n",
    "    l2 = trial.suggest_int('l2', 32, 1024)\n",
    "    l3 = trial.suggest_int('l3', 32, 1024)\n",
    "    l4 = trial.suggest_int('l4', 32, 1024)\n",
    "    l5 = trial.suggest_int('l5', 32, 1024)\n",
    "    l6 = trial.suggest_int('l6', 32, 1024)\n",
    "    l7 = trial.suggest_int('l7', 32, 1024)\n",
    "    l8 = trial.suggest_int('l8', 32, 1024)\n",
    "    l9 = trial.suggest_int('l9', 32, 1024)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 9)\n",
    "\n",
    "    Layers = [l1, l2, l3, l4, l5, l6, l7, l8, l9]\n",
    "    Layers = Layers[:1]\n",
    "    print(\"Layers: \", Layers)\n",
    "\n",
    "    mod = main(\n",
    "        t_Epochs = opt_Epochs,\n",
    "        t_Steps= opt_Steps,\n",
    "        t_Learning_Rate = opt_Learning_Rate,\n",
    "        t_Batch_Size = opt_Batch_Size,\n",
    "        t_Number_of_Noise_Batches = opt_Number_of_Noise_Batches,\n",
    "        t_Regularization_term = opt_Regularization_term,\n",
    "        t_Layers = Layers,\n",
    "        t_Noise_Dim = opt_Noise_Dim,\n",
    "        new_baseline=False,\n",
    "        logs=True,\n",
    "        model_eval_logs=False,\n",
    "    )\n",
    "    \n",
    "    data_dir = f'data{os.sep}cifar10'\n",
    "\n",
    "    transform_test = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    valid_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "    valid_dl = DataLoader(valid_ds, 256,)\n",
    "\n",
    "    exact = resnet18(num_classes = 10).to(DEVICE)\n",
    "    exact.load_state_dict(torch.load(\"ResNET18_CIFAR10_RETAIN_CLASSES.pt\", weights_only=True))\n",
    "    div = kl_divergence_between_models(\n",
    "        model1 = mod,\n",
    "        model2 = exact,\n",
    "        data_loader = valid_dl,\n",
    "    )\n",
    "\n",
    "    return div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 16:31:16,335] A new study created in memory with name: GeneratorOpti\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 |\n",
      "Steps: 5 |\n",
      "Learning Rate: 0.11465825454369884 |\n",
      "Batch Size: 51 |\n",
      "Noise Batches: 9 |\n",
      "Regularization Term: 0.06553558993493315 |\n",
      "Noise Dim: 329\n",
      "Layers:  [477]\n",
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "---Optimizing noise generator---\n",
      "Optiming loss for class 0\n",
      "Loss: 2694.703125\n",
      "Loss: 9083.310546875\n",
      "Loss: 20814.56640625\n",
      "Loss: 6954.4912109375\n",
      "Loss: 13898.6142578125\n",
      "Loss: 4336.4326171875\n",
      "Loss: 10435.720703125\n",
      "Loss: 6321.22509765625\n",
      "Loss: 4027.041748046875\n",
      "Loss: 9768.16015625\n",
      "Optiming loss for class 2\n",
      "Loss: 3541.98095703125\n",
      "Loss: 3303.551513671875\n",
      "Loss: 4005.630126953125\n",
      "Loss: 3512.423828125\n",
      "Loss: 5116.18359375\n",
      "Loss: 11598.4462890625\n",
      "Loss: 17252.89453125\n",
      "Loss: 7855.1533203125\n",
      "Loss: 9938.1123046875\n",
      "Loss: 11286.79296875\n",
      "---Impairing Phase---\n",
      "Train loss 1: 0.26202718601584435,Train Acc:8.0%\n",
      "---Repairing Phase---\n",
      "Train loss 1: 0.16379446777701379,Train Acc:10.128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 16:40:33,669] Trial 0 finished with value: 0.9663974999999996 and parameters: {'opt_Epochs': 10, 'opt_Steps': 5, 'opt_Learning_Rate': 0.11465825454369884, 'opt_Batch_Size': 51, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.06553558993493315, 'opt_Noise_Dim': 329, 'l1': 477, 'l2': 820, 'l3': 925, 'l4': 140, 'l5': 980, 'l6': 294, 'l7': 130, 'l8': 535, 'l9': 411, 'n_layers': 3}. Best is trial 0 with value: 0.9663974999999996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 |\n",
      "Steps: 7 |\n",
      "Learning Rate: 0.20207056383994298 |\n",
      "Batch Size: 94 |\n",
      "Noise Batches: 8 |\n",
      "Regularization Term: 0.20960383025524518 |\n",
      "Noise Dim: 472\n",
      "Layers:  [387]\n",
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "---Optimizing noise generator---\n",
      "Optiming loss for class 0\n",
      "Loss: 26018.478515625\n",
      "Loss: 13825.0205078125\n",
      "Loss: 18879.162109375\n",
      "Loss: 21198.26171875\n",
      "Optiming loss for class 2\n",
      "Loss: 14665.984375\n",
      "Loss: 60268.03515625\n",
      "Loss: 29081.982421875\n",
      "Loss: 57865.5390625\n",
      "---Impairing Phase---\n",
      "Train loss 1: 0.27501997631788255,Train Acc:8.838%\n",
      "---Repairing Phase---\n",
      "Train loss 1: 0.16986289055585863,Train Acc:9.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 17:21:20,963] Trial 1 finished with value: 0.9721624999999997 and parameters: {'opt_Epochs': 4, 'opt_Steps': 7, 'opt_Learning_Rate': 0.20207056383994298, 'opt_Batch_Size': 94, 'opt_Number_of_Noise_Batches': 8, 'opt_Regularization_term': 0.20960383025524518, 'opt_Noise_Dim': 472, 'l1': 387, 'l2': 640, 'l3': 483, 'l4': 810, 'l5': 116, 'l6': 643, 'l7': 855, 'l8': 847, 'l9': 104, 'n_layers': 4}. Best is trial 0 with value: 0.9663974999999996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 |\n",
      "Steps: 6 |\n",
      "Learning Rate: 0.01756754949978878 |\n",
      "Batch Size: 242 |\n",
      "Noise Batches: 9 |\n",
      "Regularization Term: 0.060799441872320475 |\n",
      "Noise Dim: 217\n",
      "Layers:  [618]\n",
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "---Optimizing noise generator---\n",
      "Optiming loss for class 0\n",
      "Loss: 188.98255920410156\n",
      "Optiming loss for class 2\n",
      "Loss: 262.0127258300781\n",
      "---Impairing Phase---\n",
      "Train loss 1: 0.2305739527630806,Train Acc:16.452%\n",
      "---Repairing Phase---\n",
      "Train loss 1: 0.1238517887210846,Train Acc:11.888%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 18:56:08,945] Trial 2 finished with value: 0.8117300000000001 and parameters: {'opt_Epochs': 1, 'opt_Steps': 6, 'opt_Learning_Rate': 0.01756754949978878, 'opt_Batch_Size': 242, 'opt_Number_of_Noise_Batches': 9, 'opt_Regularization_term': 0.060799441872320475, 'opt_Noise_Dim': 217, 'l1': 618, 'l2': 150, 'l3': 962, 'l4': 1000, 'l5': 547, 'l6': 432, 'l7': 75, 'l8': 768, 'l9': 772, 'n_layers': 4}. Best is trial 2 with value: 0.8117300000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 |\n",
      "Steps: 2 |\n",
      "Learning Rate: 0.13472848683720162 |\n",
      "Batch Size: 73 |\n",
      "Noise Batches: 10 |\n",
      "Regularization Term: 0.24240655504737732 |\n",
      "Noise Dim: 386\n",
      "Layers:  [370]\n",
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "---Optimizing noise generator---\n",
      "Optiming loss for class 0\n",
      "Loss: 11941.9521484375\n",
      "Loss: 6315.853515625\n",
      "Loss: 27457.3203125\n",
      "Loss: 406.1610107421875\n",
      "Loss: 11354.96484375\n",
      "Loss: 2388.40625\n",
      "Loss: 27567.55078125\n",
      "Loss: 2804.00048828125\n",
      "Optiming loss for class 2\n",
      "Loss: 9550.390625\n",
      "Loss: 12710.7119140625\n",
      "Loss: 14950.0166015625\n",
      "Loss: 61792.27734375\n",
      "Loss: 17384.671875\n",
      "Loss: 14655.3203125\n",
      "Loss: 35956.27734375\n",
      "Loss: 12491.017578125\n",
      "---Impairing Phase---\n",
      "Train loss 1: 0.23237045771837234,Train Acc:10.52%\n",
      "---Repairing Phase---\n",
      "Train loss 1: 0.13987509068131446,Train Acc:10.958%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 19:05:00,424] Trial 3 finished with value: 0.889345 and parameters: {'opt_Epochs': 8, 'opt_Steps': 2, 'opt_Learning_Rate': 0.13472848683720162, 'opt_Batch_Size': 73, 'opt_Number_of_Noise_Batches': 10, 'opt_Regularization_term': 0.24240655504737732, 'opt_Noise_Dim': 386, 'l1': 370, 'l2': 880, 'l3': 452, 'l4': 738, 'l5': 548, 'l6': 932, 'l7': 911, 'l8': 548, 'l9': 852, 'n_layers': 1}. Best is trial 2 with value: 0.8117300000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 |\n",
      "Steps: 4 |\n",
      "Learning Rate: 0.15256516910032245 |\n",
      "Batch Size: 184 |\n",
      "Noise Batches: 4 |\n",
      "Regularization Term: 0.23334428810975033 |\n",
      "Noise Dim: 198\n",
      "Layers:  [355]\n",
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "---Optimizing noise generator---\n",
      "Optiming loss for class 0\n",
      "Loss: 11969.7744140625\n",
      "Loss: 44739.9453125\n",
      "Loss: 20514.64453125\n",
      "Optiming loss for class 2\n",
      "Loss: 8946.8994140625\n",
      "Loss: 18545.568359375\n",
      "Loss: 14834.4599609375\n",
      "---Impairing Phase---\n",
      "Train loss 1: 0.2647082072353363,Train Acc:9.782%\n",
      "---Repairing Phase---\n",
      "Train loss 1: 0.17230711503982543,Train Acc:10.112%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-07 19:18:45,765] Trial 4 finished with value: 0.9220874999999998 and parameters: {'opt_Epochs': 3, 'opt_Steps': 4, 'opt_Learning_Rate': 0.15256516910032245, 'opt_Batch_Size': 184, 'opt_Number_of_Noise_Batches': 4, 'opt_Regularization_term': 0.23334428810975033, 'opt_Noise_Dim': 198, 'l1': 355, 'l2': 1000, 'l3': 187, 'l4': 198, 'l5': 390, 'l6': 89, 'l7': 357, 'l8': 358, 'l9': 486, 'n_layers': 8}. Best is trial 2 with value: 0.8117300000000001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'opt_Epochs': 1,\n",
       " 'opt_Steps': 6,\n",
       " 'opt_Learning_Rate': 0.01756754949978878,\n",
       " 'opt_Batch_Size': 242,\n",
       " 'opt_Number_of_Noise_Batches': 9,\n",
       " 'opt_Regularization_term': 0.060799441872320475,\n",
       " 'opt_Noise_Dim': 217,\n",
       " 'l1': 618,\n",
       " 'l2': 150,\n",
       " 'l3': 962,\n",
       " 'l4': 1000,\n",
       " 'l5': 547,\n",
       " 'l6': 432,\n",
       " 'l7': 75,\n",
       " 'l8': 768,\n",
       " 'l9': 772,\n",
       " 'n_layers': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"GeneratorOpti\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Standard Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n0 = 5000\n",
    "# n2 = 5000\n",
    "# batch_size = 128\n",
    "\n",
    "# standard_model, standard_history = main(\n",
    "#     t_Epochs = 5,\n",
    "#     t_Steps= int((n0 + n2)/(2 * batch_size)), # The Idea is to have the same amount of updates as their are samples to unlearn\n",
    "#     t_Learning_Rate = 0.1,\n",
    "#     t_Batch_Size = batch_size,\n",
    "#     t_Number_of_Noise_Batches = 10,\n",
    "#     t_Regularization_term = 0.1,\n",
    "#     t_Layers = [1000],\n",
    "#     t_Noise_Dim = 100,\n",
    "#     new_baseline=True,\n",
    "#     logs=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train = resnet18(num_classes = 10).to(DEVICE)\n",
    "train.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\",     weights_only=True))\n",
    "\n",
    "exact = resnet18(num_classes = 10).to(DEVICE)\n",
    "exact.load_state_dict(torch.load(\"ResNET18_CIFAR10_RETAIN_CLASSES.pt\",  weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import kl_divergence_between_models\n",
    "import os\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "batch_size = 256\n",
    "data_dir = f'data{os.sep}cifar10'\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "valid_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, shuffle=False)\n",
    "\n",
    "kl_divergence_between_models(model1 = train, model2 = train, data_loader = valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence_between_models(model1=exact, model2=exact, data_loader=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.395605000000001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence_between_models(model1=train, model2=exact, data_loader=valid_dl)\n",
    "# 407764079971736.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2414749999999994"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence_between_models(model1=exact, model2=train, data_loader=valid_dl)\n",
    "# 336395501025684.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
