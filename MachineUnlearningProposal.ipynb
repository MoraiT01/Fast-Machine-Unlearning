{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9584dc74",
   "metadata": {},
   "source": [
    "# Machine Unlearning + Noise Generator\n",
    "\n",
    "This is a copy of the original `Machine Unlearning.ipynb` notebook, with the key difference of using a different way of generating the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e828435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "train_new_one = False\n",
    "# torch.manual_seed(100)\n",
    "# After I optimize the Hyperparameters, I want to calculate at least 30 models, to chech the average performance\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73d496",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e04a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def training_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "    out = model(images)                  \n",
    "    loss = F.cross_entropy(out, labels) \n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "    out = model(images)                    \n",
    "    loss = F.cross_entropy(out, labels)   \n",
    "    acc = accuracy(out, labels)\n",
    "    return {'Loss': loss.detach(), 'Acc': acc}\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   \n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      \n",
    "    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "    \n",
    "def distance(model,model0):\n",
    "    distance=0\n",
    "    normalization=0\n",
    "    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n",
    "        space='  ' if 'bias' in k else ''\n",
    "        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n",
    "        current_norm=p.data0.pow(2).sum().item()\n",
    "        distance+=current_dist\n",
    "        normalization+=current_norm\n",
    "    print(f'Distance: {np.sqrt(distance)}')\n",
    "    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n",
    "    return 1.0*np.sqrt(distance/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec89a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            lrs.append(get_lr(optimizer))\n",
    "            \n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d890",
   "metadata": {},
   "source": [
    "## Train/Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32155eed",
   "metadata": {},
   "source": [
    "### load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41e0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./cifar10.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11114/3544667939.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path='./data')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n",
      "['bird', 'deer', 'horse', 'automobile', 'frog', 'airplane', 'truck', 'cat', 'dog', 'ship']\n"
     ]
    }
   ],
   "source": [
    "# Dowload the dataset\n",
    "if os.path.exists(\"data/cifar10\"):\n",
    "    dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "    download_url(dataset_url, '.')\n",
    "\n",
    "    # Extract from archive\n",
    "    with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "        tar.extractall(path='./data')\n",
    "        \n",
    "    # Look into the data directory\n",
    "    data_dir = './data/cifar10'\n",
    "    print(os.listdir(data_dir))\n",
    "    classes = os.listdir(data_dir + \"/train\")\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29db69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(data_dir+'/train', transform_train)\n",
    "valid_ds = ImageFolder(data_dir+'/test', transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7844cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f4d2b",
   "metadata": {},
   "source": [
    "### Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54996a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = resnet18(num_classes = 10).to(DEVICE)\n",
    "\n",
    "epochs = 40\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6352284",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'exists'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.exists(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"):\n",
    "    history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                                grad_clip=grad_clip, \n",
    "                                weight_decay=weight_decay, \n",
    "                                opt_func=opt_func)\n",
    "\n",
    "    torch.save(model.state_dict(), \"ResNET18_CIFAR10_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980397d",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3769eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n",
    "    history = [evaluate(model, valid_dl)]\n",
    "    history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e31ccb",
   "metadata": {},
   "source": [
    "## Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4696560",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d212fd",
   "metadata": {},
   "source": [
    "Originally used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f88a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining the noise structure\n",
    "# class Noise(nn.Module):\n",
    "#     def __init__(self, *dim):\n",
    "#         super().__init__()\n",
    "#         self.noise = torch.nn.Parameter(torch.randn(*dim), requires_grad = True)\n",
    "        \n",
    "#     def forward(self):\n",
    "#         return self.noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c939dd9",
   "metadata": {},
   "source": [
    "Trying a different approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287dac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network module for generating noise patterns\n",
    "    through a series of fully connected layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            dim_out: list,\n",
    "            dim_hidden: list = [1000],\n",
    "            dim_start: int = 100,\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initialize the NoiseGenerator.\n",
    "\n",
    "        Parameters:\n",
    "            dim_out (list): The output dimensions for the generated noise.\n",
    "            dim_hidden (list): The dimensions of hidden layers, defaults to [1000].\n",
    "            dim_start (int): The initial dimension of random noise, defaults to 100.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dim = dim_out\n",
    "        self.start_dims = dim_start  # Initial dimension of random noise\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.layers = {}\n",
    "        self.layers[\"l1\"] = nn.Linear(self.start_dims, dim_hidden[0])\n",
    "        last = dim_hidden[0]\n",
    "        for idx in range(len(dim_hidden)-1):\n",
    "            self.layers[f\"l{idx+2}\"] = nn.Linear(dim_hidden[idx], dim_hidden[idx+1])\n",
    "            last = dim_hidden[idx+1]\n",
    "\n",
    "        # Define output layer\n",
    "        self.f_out = nn.Linear(last, math.prod(self.dim))        \n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward pass to transform random noise into structured output.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The reshaped tensor with specified output dimensions.\n",
    "        \"\"\"\n",
    "        # Generate random starting noise\n",
    "        x = torch.randn(self.start_dims)\n",
    "        x = x.flatten()\n",
    "\n",
    "        # Transform noise into learnable patterns\n",
    "        for layer in self.layers.keys():\n",
    "            x = self.layers[layer](x)\n",
    "            x = torch.relu(x)\n",
    "\n",
    "        # Apply output layer\n",
    "        x = self.f_out(x)\n",
    "\n",
    "        # Reshape tensor to the specified dimensions\n",
    "        reshaped_tensor = x.view(self.dim)\n",
    "        return reshaped_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff85afe",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65082f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all classes\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# classes which are required to un-learn\n",
    "classes_to_forget = [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfedd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classwise list of samples\n",
    "num_classes = 10\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edbda37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some samples from retain classes\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "retain_samples = []\n",
    "for i in range(len(classes)):\n",
    "    if classes[i] not in classes_to_forget:\n",
    "        retain_samples += classwise_train[i][:num_samples_per_class]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70736605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain validation set\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "            \n",
    "# forget validation set\n",
    "forget_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "            \n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9afbe",
   "metadata": {},
   "source": [
    "### Training the Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcc11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11114/1528628438.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model = resnet18(num_classes = 10).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1170217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 4.77 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if train_new_one:\n",
    "    noises = {}\n",
    "    for cls in classes_to_forget:\n",
    "        print(\"Optiming loss for class {}\".format(cls))\n",
    "        noises[cls] = Noise(batch_size, 3, 32, 32)\n",
    "        opt = torch.optim.Adam(noises[cls].parameters(), lr = 0.1)\n",
    "\n",
    "        num_epochs = 5\n",
    "        num_steps = 8\n",
    "        class_label = cls\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = []\n",
    "            for batch in range(num_steps):\n",
    "                inputs = noises[cls]()\n",
    "                labels = torch.zeros(batch_size)+class_label\n",
    "                outputs = model(inputs)\n",
    "                loss = -F.cross_entropy(outputs, labels.long()) + 0.1*torch.mean(torch.sum(torch.square(inputs), [1, 2, 3]))\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                total_loss.append(loss.cpu().detach().numpy())\n",
    "            print(\"Loss: {}\".format(np.mean(total_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08aa35",
   "metadata": {},
   "source": [
    "## Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09feaed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noises' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noises' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 256\n",
    "noisy_data = []\n",
    "num_batches = 20\n",
    "class_num = 0\n",
    "\n",
    "for cls in classes_to_forget:\n",
    "    for i in range(num_batches):\n",
    "        batch = noises[cls]().cpu().detach()\n",
    "        for i in range(batch[0].size(0)):\n",
    "            noisy_data.append((batch[i], torch.tensor(class_num)))\n",
    "\n",
    "other_samples = []\n",
    "for i in range(len(retain_samples)):\n",
    "    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][1])))\n",
    "noisy_data += other_samples\n",
    "noisy_loader = torch.utils.data.DataLoader(noisy_data, batch_size=256, shuffle = True)\n",
    "\n",
    "\n",
    "if train_new_one:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.02)\n",
    "\n",
    "    for epoch in range(1):  \n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0\n",
    "        for i, data in enumerate(noisy_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs,torch.tensor(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            out = torch.argmax(outputs.detach(),dim=1)\n",
    "            assert out.shape==labels.shape\n",
    "            running_acc += (labels==out).sum().item()\n",
    "        print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4a772",
   "metadata": {},
   "source": [
    "### Performance after Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfcffec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "    print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabdfc92",
   "metadata": {},
   "source": [
    "## Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2abac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'other_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'other_samples' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "heal_loader = torch.utils.data.DataLoader(other_samples, batch_size=256, shuffle = True)\n",
    "if train_new_one:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "    for epoch in range(1):  \n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0\n",
    "        for i, data in enumerate(heal_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs,torch.tensor(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            out = torch.argmax(outputs.detach(),dim=1)\n",
    "            assert out.shape==labels.shape\n",
    "            running_acc += (labels==out).sum().item()\n",
    "        print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee6e55",
   "metadata": {},
   "source": [
    "### Performance after Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e74aa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "    print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c19a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def load_models_dict(path: str=\"data/new/models\") -> Dict[str, torch.nn.Module]:\n",
    "    de = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(num_classes = 10).to(de)\n",
    "    \n",
    "    # load all the models\n",
    "    md = {}\n",
    "    for list in os.listdir(path):\n",
    "        \n",
    "        model.load_state_dict(torch.load(f=os.path.join(path, list), weights_only=True))\n",
    "        model.eval()\n",
    "        md[len(md)] = model\n",
    "\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2281224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training new ResNet18---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.01000, train_loss: 1.8150, val_loss: 1.3837, val_acc: 0.4840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], last_lr: 0.01000, train_loss: 1.3237, val_loss: 1.2356, val_acc: 0.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], last_lr: 0.01000, train_loss: 1.0756, val_loss: 1.0671, val_acc: 0.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], last_lr: 0.01000, train_loss: 0.9295, val_loss: 1.0373, val_acc: 0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], last_lr: 0.01000, train_loss: 0.8425, val_loss: 0.9721, val_acc: 0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], last_lr: 0.01000, train_loss: 0.7760, val_loss: 0.8967, val_acc: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:14<00:00, 13.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], last_lr: 0.01000, train_loss: 0.7330, val_loss: 0.9646, val_acc: 0.6755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], last_lr: 0.01000, train_loss: 0.6913, val_loss: 0.8313, val_acc: 0.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], last_lr: 0.01000, train_loss: 0.6631, val_loss: 0.8726, val_acc: 0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:14<00:00, 13.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], last_lr: 0.01000, train_loss: 0.6406, val_loss: 0.8511, val_acc: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], last_lr: 0.01000, train_loss: 0.6187, val_loss: 0.8193, val_acc: 0.7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], last_lr: 0.01000, train_loss: 0.5948, val_loss: 0.7799, val_acc: 0.7355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], last_lr: 0.01000, train_loss: 0.5750, val_loss: 0.8956, val_acc: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], last_lr: 0.01000, train_loss: 0.5627, val_loss: 0.7698, val_acc: 0.7373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], last_lr: 0.01000, train_loss: 0.5488, val_loss: 0.8244, val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], last_lr: 0.01000, train_loss: 0.5327, val_loss: 0.7588, val_acc: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 15.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], last_lr: 0.01000, train_loss: 0.5202, val_loss: 0.8447, val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], last_lr: 0.01000, train_loss: 0.5159, val_loss: 0.8503, val_acc: 0.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], last_lr: 0.01000, train_loss: 0.5033, val_loss: 0.8094, val_acc: 0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], last_lr: 0.01000, train_loss: 0.4908, val_loss: 0.8439, val_acc: 0.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], last_lr: 0.00500, train_loss: 0.3288, val_loss: 0.7740, val_acc: 0.7622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], last_lr: 0.00500, train_loss: 0.2863, val_loss: 0.8163, val_acc: 0.7537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:12<00:00, 15.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], last_lr: 0.00500, train_loss: 0.2728, val_loss: 0.8696, val_acc: 0.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:13<00:00, 14.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], last_lr: 0.00500, train_loss: 0.2602, val_loss: 0.8737, val_acc: 0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:14<00:00, 13.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], last_lr: 0.00250, train_loss: 0.1388, val_loss: 0.9159, val_acc: 0.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], last_lr: 0.00250, train_loss: 0.0804, val_loss: 1.0484, val_acc: 0.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], last_lr: 0.00250, train_loss: 0.0839, val_loss: 1.1328, val_acc: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], last_lr: 0.00250, train_loss: 0.0917, val_loss: 1.1386, val_acc: 0.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], last_lr: 0.00125, train_loss: 0.0400, val_loss: 1.1208, val_acc: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], last_lr: 0.00125, train_loss: 0.0128, val_loss: 1.1888, val_acc: 0.7748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], last_lr: 0.00125, train_loss: 0.0067, val_loss: 1.2339, val_acc: 0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], last_lr: 0.00125, train_loss: 0.0045, val_loss: 1.2747, val_acc: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], last_lr: 0.00063, train_loss: 0.0033, val_loss: 1.2798, val_acc: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], last_lr: 0.00063, train_loss: 0.0024, val_loss: 1.3059, val_acc: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], last_lr: 0.00063, train_loss: 0.0023, val_loss: 1.3201, val_acc: 0.7788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], last_lr: 0.00063, train_loss: 0.0018, val_loss: 1.3253, val_acc: 0.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], last_lr: 0.00031, train_loss: 0.0017, val_loss: 1.3333, val_acc: 0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], last_lr: 0.00031, train_loss: 0.0016, val_loss: 1.3473, val_acc: 0.7783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], last_lr: 0.00031, train_loss: 0.0013, val_loss: 1.3514, val_acc: 0.7799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 196/196 [00:15<00:00, 12.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], last_lr: 0.00031, train_loss: 0.0012, val_loss: 1.3530, val_acc: 0.7788\n",
      "---Training new Exact Unlearned ResNet18---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.01000, train_loss: 1.6355, val_loss: 1.3506, val_acc: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], last_lr: 0.01000, train_loss: 1.1483, val_loss: 1.2730, val_acc: 0.5452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], last_lr: 0.01000, train_loss: 0.9227, val_loss: 1.0540, val_acc: 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], last_lr: 0.01000, train_loss: 0.8070, val_loss: 0.7863, val_acc: 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], last_lr: 0.01000, train_loss: 0.7170, val_loss: 0.7961, val_acc: 0.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:12<00:00, 12.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], last_lr: 0.01000, train_loss: 0.6573, val_loss: 0.7451, val_acc: 0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 14.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], last_lr: 0.01000, train_loss: 0.6029, val_loss: 0.7351, val_acc: 0.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], last_lr: 0.01000, train_loss: 0.5723, val_loss: 0.7761, val_acc: 0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], last_lr: 0.01000, train_loss: 0.5417, val_loss: 0.8113, val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 14.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], last_lr: 0.01000, train_loss: 0.5223, val_loss: 0.6803, val_acc: 0.7534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], last_lr: 0.01000, train_loss: 0.4954, val_loss: 0.6917, val_acc: 0.7568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], last_lr: 0.01000, train_loss: 0.4739, val_loss: 0.6858, val_acc: 0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], last_lr: 0.01000, train_loss: 0.4613, val_loss: 0.6966, val_acc: 0.7624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], last_lr: 0.01000, train_loss: 0.4432, val_loss: 0.7155, val_acc: 0.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], last_lr: 0.00500, train_loss: 0.2938, val_loss: 0.6755, val_acc: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], last_lr: 0.00500, train_loss: 0.2469, val_loss: 0.7255, val_acc: 0.7768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], last_lr: 0.00500, train_loss: 0.2349, val_loss: 0.7595, val_acc: 0.7837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], last_lr: 0.00500, train_loss: 0.2231, val_loss: 0.7274, val_acc: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], last_lr: 0.00500, train_loss: 0.1990, val_loss: 0.8551, val_acc: 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], last_lr: 0.00250, train_loss: 0.1018, val_loss: 0.8189, val_acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], last_lr: 0.00250, train_loss: 0.0457, val_loss: 0.9345, val_acc: 0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], last_lr: 0.00250, train_loss: 0.0371, val_loss: 1.0381, val_acc: 0.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], last_lr: 0.00250, train_loss: 0.0666, val_loss: 1.0284, val_acc: 0.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], last_lr: 0.00125, train_loss: 0.0383, val_loss: 0.9752, val_acc: 0.7946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], last_lr: 0.00125, train_loss: 0.0102, val_loss: 1.0096, val_acc: 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], last_lr: 0.00125, train_loss: 0.0046, val_loss: 1.0562, val_acc: 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], last_lr: 0.00125, train_loss: 0.0038, val_loss: 1.1050, val_acc: 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], last_lr: 0.00063, train_loss: 0.0025, val_loss: 1.1123, val_acc: 0.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], last_lr: 0.00063, train_loss: 0.0017, val_loss: 1.1173, val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], last_lr: 0.00063, train_loss: 0.0016, val_loss: 1.1229, val_acc: 0.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], last_lr: 0.00063, train_loss: 0.0019, val_loss: 1.1349, val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], last_lr: 0.00031, train_loss: 0.0013, val_loss: 1.1378, val_acc: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], last_lr: 0.00031, train_loss: 0.0014, val_loss: 1.1467, val_acc: 0.7977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:09<00:00, 15.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], last_lr: 0.00031, train_loss: 0.0011, val_loss: 1.1566, val_acc: 0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], last_lr: 0.00031, train_loss: 0.0010, val_loss: 1.1640, val_acc: 0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], last_lr: 0.00016, train_loss: 0.0009, val_loss: 1.1569, val_acc: 0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], last_lr: 0.00016, train_loss: 0.0009, val_loss: 1.1768, val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], last_lr: 0.00016, train_loss: 0.0008, val_loss: 1.1717, val_acc: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], last_lr: 0.00016, train_loss: 0.0008, val_loss: 1.1722, val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 157/157 [00:10<00:00, 15.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], last_lr: 0.00008, train_loss: 0.0007, val_loss: 1.1749, val_acc: 0.7978\n",
      "[{'Loss': 1.352973222732544, 'Acc': 0.7788200974464417}]\n",
      "Performance of Standard Forget Model on Forget Class\n",
      "Accuracy: 1.1944110505282879\n",
      "Loss: 7.286940574645996\n",
      "Performance of Standard Forget Model on Retain Class\n",
      "Accuracy: 69.08203363418579\n",
      "Loss: 0.8631603717803955\n",
      "Performance of Standard Forget Model on Forget Class\n",
      "Accuracy: 0.0\n",
      "Loss: 9.606056213378906\n",
      "Performance of Standard Forget Model on Retain Class\n",
      "Accuracy: 71.56982421875\n",
      "Loss: 0.810927152633667\n"
     ]
    }
   ],
   "source": [
    "from src.fyemu_tunable import main\n",
    "\n",
    "if True:\n",
    "    for i in range(1):\n",
    "        model = main()\n",
    "        # TODO\n",
    "        # After Finetuning is done\n",
    "        # write this !!!!!!!!!!!!!!!\n",
    "        # Save the model\n",
    "        # if not os.path.exists(\"data/new/models\"):\n",
    "        #    os.makedirs(\"data/new/models\")\n",
    "        # n = len(os.listdir(\"data/new/models\"))\n",
    "        # torch.save(model.state_dict(), f\"data/new/models/ResNET18_CIFAR10_UN_{n}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11c592",
   "metadata": {},
   "source": [
    "___\n",
    "## Evaluate multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee59dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tarfile\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Firstly, all the data\n",
    "class SubData(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "\n",
    "        img = Image.open(f\"{path}\").convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        label = torch.tensor(label)\n",
    "        return img.to(self.device), label.to(self.device)\n",
    "\n",
    "data_dir = f'data{os.sep}cifar10'\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# classes which are required to un-learn\n",
    "classes_to_forget = [0, 2]\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_train = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb5e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_all_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "valid_all_dl = DataLoader(valid_all_ds, 256,)\n",
    "\n",
    "train_all_ds = ImageFolder(data_dir+f'{os.sep}train', transform_train)\n",
    "train_all_dl = DataLoader(train_all_ds, 256,)\n",
    "\n",
    "rt_tr = {}\n",
    "for t, l in train_all_ds.imgs:\n",
    "    if l not in classes_to_forget:\n",
    "        rt_tr[len(rt_tr)] = (t, l)\n",
    "rt_vl = {}\n",
    "for t, l in valid_all_ds.imgs:\n",
    "    if l not in classes_to_forget:\n",
    "        rt_vl[len(rt_vl)] = (t, l)\n",
    "\n",
    "train_retain_ds = SubData(rt_tr, transform_train)\n",
    "valid_retain_ds = SubData(rt_vl, transform_test)\n",
    "\n",
    "train_retain_dl = DataLoader(train_retain_ds, 256, shuffle=True)\n",
    "valid_retain_dl = DataLoader(valid_retain_ds, 256*2)\n",
    "\n",
    "rt_tr = {}\n",
    "for t, l in train_all_ds.imgs:\n",
    "    if l in classes_to_forget:\n",
    "        rt_tr[len(rt_tr)] = (t, l)\n",
    "rt_vl = {}\n",
    "for t, l in valid_all_ds.imgs:\n",
    "    if l in classes_to_forget:\n",
    "        rt_vl[len(rt_vl)] = (t, l)\n",
    "\n",
    "train_forget_ds = SubData(rt_tr, transform_train)\n",
    "valid_forget_ds = SubData(rt_vl, transform_test)\n",
    "\n",
    "train_forget_dl = DataLoader(train_forget_ds, 256, shuffle=True)\n",
    "valid_forget_dl = DataLoader(train_forget_ds, 256*2)\n",
    "\n",
    "loaders = {\n",
    "    0: train_all_dl,\n",
    "    1: valid_all_dl,\n",
    "    2: train_retain_dl,\n",
    "    3: valid_retain_dl,\n",
    "    4: train_forget_dl,\n",
    "    5: valid_forget_dl,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5c37661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.metrics\n",
    "from src.fyemu_tunable import evaluate\n",
    "from torchvision.models import resnet18\n",
    "paper_ms    = load_models_dict(path=\"data/paper/models\")\n",
    "gemu_ms     = load_models_dict(path=\"data/new/models\")\n",
    "\n",
    "exact = resnet18(num_classes = 10).to(DEVICE)\n",
    "exact.load_state_dict(torch.load(\"ResNET18_CIFAR10_RETRAIN_CLASSES.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdd61db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Loss': 2.209007740020752, 'Acc': 0.8007015585899353},\n",
       " 1: {'Loss': 3.2875797748565674, 'Acc': 0.626953125},\n",
       " 2: {'Loss': 0.0003276505449321121, 'Acc': 1.0},\n",
       " 3: {'Loss': 1.3938783407211304, 'Acc': 0.778637707233429},\n",
       " 4: {'Loss': 11.116077423095703, 'Acc': 0.0},\n",
       " 5: {'Loss': 11.099096298217773, 'Acc': 0.0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run(model, loaders):\n",
    "    results = {}\n",
    "    for name, loader in loaders.items():\n",
    "        results[name] = evaluate(model, loader)\n",
    "\n",
    "    return results\n",
    "run(exact, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5922b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433,\n",
       "  0.8722768281491433],\n",
       " 1: [0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567,\n",
       "  0.9261725828051567],\n",
       " 2: [0.692274327111092,\n",
       "  0.6934691697928559,\n",
       "  0.6922295180855281,\n",
       "  0.6929352363203743,\n",
       "  0.6926514867005076,\n",
       "  0.6926629486357332,\n",
       "  0.6929997133601247,\n",
       "  0.6929697206445561,\n",
       "  0.6923859753426469,\n",
       "  0.6926128484640914,\n",
       "  0.6918048475198684,\n",
       "  0.6922287079179362,\n",
       "  0.692776116975553,\n",
       "  0.6917804187270488,\n",
       "  0.6922854075006617,\n",
       "  0.6919692807896128,\n",
       "  0.6930914657890419,\n",
       "  0.6920182260738055,\n",
       "  0.6914577123465809,\n",
       "  0.6921187119119488,\n",
       "  0.6919771873267594,\n",
       "  0.6908970247408388,\n",
       "  0.6930839929990704,\n",
       "  0.6935819584852572,\n",
       "  0.691885303160188,\n",
       "  0.6925740450810477,\n",
       "  0.6908824857632828,\n",
       "  0.6929645094142597,\n",
       "  0.6924099656426983,\n",
       "  0.6929434302506173],\n",
       " 3: [0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703,\n",
       "  0.7576142959296703],\n",
       " 4: [1.5962596654891972,\n",
       "  1.5894047409296035,\n",
       "  1.580485013127327,\n",
       "  1.597350889444351,\n",
       "  1.5951108455657956,\n",
       "  1.5758659034967422,\n",
       "  1.600454917550087,\n",
       "  1.6045708507299428,\n",
       "  1.5875314325094223,\n",
       "  1.5998621881008153,\n",
       "  1.5868227869272231,\n",
       "  1.596610736846924,\n",
       "  1.5814905375242232,\n",
       "  1.5841958999633792,\n",
       "  1.609160786867142,\n",
       "  1.5871921628713608,\n",
       "  1.6023470997810365,\n",
       "  1.584856879711151,\n",
       "  1.5973210453987123,\n",
       "  1.582861390709877,\n",
       "  1.5887527048587797,\n",
       "  1.5979705184698108,\n",
       "  1.587375712394714,\n",
       "  1.583232843875885,\n",
       "  1.5768936142325398,\n",
       "  1.5793008893728255,\n",
       "  1.5871966809034348,\n",
       "  1.58780879676342,\n",
       "  1.5996512383222579,\n",
       "  1.599434021115303],\n",
       " 5: [1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213,\n",
       "  1.5876486957073213]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divs_per_loader_gen = {}\n",
    "for name, loader in loaders.items():\n",
    "    kl_divs_per_loader_gen[name] = [src.metrics.kl_divergence_between_models(exact, gemu_ms[i], data_loader=loader, device=DEVICE) for i in gemu_ms.keys()]\n",
    "kl_divs_per_loader_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ec23f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093],\n",
       " 1: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093],\n",
       " 2: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093],\n",
       " 3: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093],\n",
       " 4: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093],\n",
       " 5: [1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093,\n",
       "  1.4823955297470093]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divs_per_loader_paper = {}\n",
    "for name, loader in loaders.items():\n",
    "    kl_divs_per_loader_paper[name] = [src.metrics.kl_divergence_between_models(exact, paper_ms[i], data_loader=loader, device=DEVICE) for i in paper_ms.keys()]\n",
    "kl_divs_per_loader_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095208fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Literal\n",
    "\n",
    "def create_boxplots(score_lists: Dict[str, List[float]], title: str = 'Box Plot of Accuracy Scores for Different Models', evaluation: Literal[\"Accuracy\", \"Loss\"] = \"Accuracy\") -> None:\n",
    "    \"\"\"Create a box plot of accuracy scores for each parsed list in the diconary.\"\"\"\n",
    "\n",
    "    # Prepare data for the box plot\n",
    "    data = [scores for scores in score_lists.values()]\n",
    "    labels = list(score_lists.keys())\n",
    "\n",
    "    # Create the box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(data, labels=labels, patch_artist=True)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Subsets')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.ylabel(f'{evaluation} Score')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7b932",
   "metadata": {},
   "source": [
    "### Accuracy Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47c7551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tarfile\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data_classes = {}\n",
    "for c in classes:\n",
    "    data_classes[c] = {}\n",
    "    for t, l in valid_all_ds.imgs:\n",
    "        if l == c:\n",
    "            data_classes[c][len(data_classes[c])] = (t, l)\n",
    "\n",
    "data_dl_classes = {c: DataLoader(SubData(data_classes[c], transform_test), 256) for c in classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4887f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accs_paper = {c: [] for c in classes}\n",
    "for idx, model in paper_ms.items():\n",
    "    model.eval()\n",
    "    accs = run(model, data_dl_classes)\n",
    "    for c, acc in accs.items():\n",
    "        class_accs_paper[c].append(acc[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accs_gemu = {c: [] for c in classes}\n",
    "for idx, model in gemu_ms.items():\n",
    "    model.eval()\n",
    "    accs = run(model, data_dl_classes)\n",
    "    for c, acc in accs.items():\n",
    "        class_accs_gemu[c].append(acc[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(class_accs_paper, \"Box Plot of Accuracy Scores for 30 Models using FYEMU\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(class_accs_gemu, \"Box Plot of Accuracy Scores for 30 Models using GEMU\", \"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
