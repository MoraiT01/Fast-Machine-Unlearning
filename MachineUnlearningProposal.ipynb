{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9584dc74",
   "metadata": {},
   "source": [
    "# Machine Unlearning + Noise Generator\n",
    "\n",
    "This is a copy of the original `Machine Unlearning.ipynb` notebook, with the key difference of using a different way of generating the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e828435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "train_new_one = False\n",
    "# torch.manual_seed(100)\n",
    "# After I optimize the Hyperparameters, I want to calculate at least 30 models, to chech the average performance\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73d496",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e04a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def training_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "    out = model(images)                  \n",
    "    loss = F.cross_entropy(out, labels) \n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "    out = model(images)                    \n",
    "    loss = F.cross_entropy(out, labels)   \n",
    "    acc = accuracy(out, labels)\n",
    "    return {'Loss': loss.detach(), 'Acc': acc}\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   \n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      \n",
    "    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "    \n",
    "def distance(model,model0):\n",
    "    distance=0\n",
    "    normalization=0\n",
    "    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n",
    "        space='  ' if 'bias' in k else ''\n",
    "        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n",
    "        current_norm=p.data0.pow(2).sum().item()\n",
    "        distance+=current_dist\n",
    "        normalization+=current_norm\n",
    "    print(f'Distance: {np.sqrt(distance)}')\n",
    "    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n",
    "    return 1.0*np.sqrt(distance/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec89a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            lrs.append(get_lr(optimizer))\n",
    "            \n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d890",
   "metadata": {},
   "source": [
    "## Train/Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32155eed",
   "metadata": {},
   "source": [
    "### load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload the dataset\n",
    "if os.path.exists(\"data/cifar10\"):\n",
    "    dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "    download_url(dataset_url, '.')\n",
    "\n",
    "    # Extract from archive\n",
    "    with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "        tar.extractall(path='./data')\n",
    "        \n",
    "    # Look into the data directory\n",
    "    data_dir = './data/cifar10'\n",
    "    print(os.listdir(data_dir))\n",
    "    classes = os.listdir(data_dir + \"/train\")\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(data_dir+'/train', transform_train)\n",
    "valid_ds = ImageFolder(data_dir+'/test', transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f4d2b",
   "metadata": {},
   "source": [
    "### Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54996a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = resnet18(num_classes = 10).to(DEVICE = DEVICE)\n",
    "\n",
    "epochs = 40\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6352284",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if os.exists(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"):\n",
    "    history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                                grad_clip=grad_clip, \n",
    "                                weight_decay=weight_decay, \n",
    "                                opt_func=opt_func)\n",
    "\n",
    "    torch.save(model.state_dict(), \"ResNET18_CIFAR10_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980397d",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3769eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n",
    "    history = [evaluate(model, valid_dl)]\n",
    "    history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e31ccb",
   "metadata": {},
   "source": [
    "## Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4696560",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d212fd",
   "metadata": {},
   "source": [
    "Originally used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f88a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining the noise structure\n",
    "# class Noise(nn.Module):\n",
    "#     def __init__(self, *dim):\n",
    "#         super().__init__()\n",
    "#         self.noise = torch.nn.Parameter(torch.randn(*dim), requires_grad = True)\n",
    "        \n",
    "#     def forward(self):\n",
    "#         return self.noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c939dd9",
   "metadata": {},
   "source": [
    "Trying a different approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287dac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network module for generating noise patterns\n",
    "    through a series of fully connected layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            dim_out: list,\n",
    "            dim_hidden: list = [1000],\n",
    "            dim_start: int = 100,\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initialize the NoiseGenerator.\n",
    "\n",
    "        Parameters:\n",
    "            dim_out (list): The output dimensions for the generated noise.\n",
    "            dim_hidden (list): The dimensions of hidden layers, defaults to [1000].\n",
    "            dim_start (int): The initial dimension of random noise, defaults to 100.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dim = dim_out\n",
    "        self.start_dims = dim_start  # Initial dimension of random noise\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.layers = {}\n",
    "        self.layers[\"l1\"] = nn.Linear(self.start_dims, dim_hidden[0])\n",
    "        last = dim_hidden[0]\n",
    "        for idx in range(len(dim_hidden)-1):\n",
    "            self.layers[f\"l{idx+2}\"] = nn.Linear(dim_hidden[idx], dim_hidden[idx+1])\n",
    "            last = dim_hidden[idx+1]\n",
    "\n",
    "        # Define output layer\n",
    "        self.f_out = nn.Linear(last, math.prod(self.dim))        \n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward pass to transform random noise into structured output.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The reshaped tensor with specified output dimensions.\n",
    "        \"\"\"\n",
    "        # Generate random starting noise\n",
    "        x = torch.randn(self.start_dims)\n",
    "        x = x.flatten()\n",
    "\n",
    "        # Transform noise into learnable patterns\n",
    "        for layer in self.layers.keys():\n",
    "            x = self.layers[layer](x)\n",
    "            x = torch.relu(x)\n",
    "\n",
    "        # Apply output layer\n",
    "        x = self.f_out(x)\n",
    "\n",
    "        # Reshape tensor to the specified dimensions\n",
    "        reshaped_tensor = x.view(self.dim)\n",
    "        return reshaped_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff85afe",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65082f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all classes\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# classes which are required to un-learn\n",
    "classes_to_forget = [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classwise list of samples\n",
    "num_classes = 10\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbda37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some samples from retain classes\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "retain_samples = []\n",
    "for i in range(len(classes)):\n",
    "    if classes[i] not in classes_to_forget:\n",
    "        retain_samples += classwise_train[i][:num_samples_per_class]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70736605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain validation set\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "            \n",
    "# forget validation set\n",
    "forget_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "            \n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9afbe",
   "metadata": {},
   "source": [
    "### Training the Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model = resnet18(num_classes = 10).to(DEVICE = DEVICE)\n",
    "model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_new_one:\n",
    "    noises = {}\n",
    "    for cls in classes_to_forget:\n",
    "        print(\"Optiming loss for class {}\".format(cls))\n",
    "        noises[cls] = Noise(batch_size, 3, 32, 32)\n",
    "        opt = torch.optim.Adam(noises[cls].parameters(), lr = 0.1)\n",
    "\n",
    "        num_epochs = 5\n",
    "        num_steps = 8\n",
    "        class_label = cls\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = []\n",
    "            for batch in range(num_steps):\n",
    "                inputs = noises[cls]()\n",
    "                labels = torch.zeros(batch_size)+class_label\n",
    "                outputs = model(inputs)\n",
    "                loss = -F.cross_entropy(outputs, labels.long()) + 0.1*torch.mean(torch.sum(torch.square(inputs), [1, 2, 3]))\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                total_loss.append(loss.cpu().detach().numpy())\n",
    "            print(\"Loss: {}\".format(np.mean(total_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08aa35",
   "metadata": {},
   "source": [
    "## Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09feaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 256\n",
    "noisy_data = []\n",
    "num_batches = 20\n",
    "class_num = 0\n",
    "\n",
    "for cls in classes_to_forget:\n",
    "    for i in range(num_batches):\n",
    "        batch = noises[cls]().cpu().detach()\n",
    "        for i in range(batch[0].size(0)):\n",
    "            noisy_data.append((batch[i], torch.tensor(class_num)))\n",
    "\n",
    "other_samples = []\n",
    "for i in range(len(retain_samples)):\n",
    "    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][1])))\n",
    "noisy_data += other_samples\n",
    "noisy_loader = torch.utils.data.DataLoader(noisy_data, batch_size=256, shuffle = True)\n",
    "\n",
    "\n",
    "if train_new_one:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.02)\n",
    "\n",
    "    for epoch in range(1):  \n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0\n",
    "        for i, data in enumerate(noisy_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs,torch.tensor(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            out = torch.argmax(outputs.detach(),dim=1)\n",
    "            assert out.shape==labels.shape\n",
    "            running_acc += (labels==out).sum().item()\n",
    "        print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4a772",
   "metadata": {},
   "source": [
    "### Performance after Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcffec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "    print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabdfc92",
   "metadata": {},
   "source": [
    "## Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2abac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "heal_loader = torch.utils.data.DataLoader(other_samples, batch_size=256, shuffle = True)\n",
    "if train_new_one:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "    for epoch in range(1):  \n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0\n",
    "        for i, data in enumerate(heal_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs,torch.tensor(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            out = torch.argmax(outputs.detach(),dim=1)\n",
    "            assert out.shape==labels.shape\n",
    "            running_acc += (labels==out).sum().item()\n",
    "        print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee6e55",
   "metadata": {},
   "source": [
    "### Performance after Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74aa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_one:\n",
    "    print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "    print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "    print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def load_models_dict(path: str=\"data/new/models\") -> Dict[str, torch.nn.Module]:\n",
    "    de = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(num_classes = 10).to(de)\n",
    "    \n",
    "    # load all the models\n",
    "    md = {}\n",
    "    for list in os.listdir(path):\n",
    "        \n",
    "        model.load_state_dict(torch.load(f=os.path.join(path, list), weights_only=True))\n",
    "        model.eval()\n",
    "        md[len(md)] = model\n",
    "\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2281224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fyemu_tunable import main\n",
    "\n",
    "for i in range(10):\n",
    "    model = main()\n",
    "\n",
    "    # Save the model\n",
    "    if not os.path.exists(\"data/new/models\"):\n",
    "        os.makedirs(\"data/new/models\")\n",
    "    n = len(os.listdir(\"data/new/models\"))\n",
    "    torch.save(model.state_dict(), f\"data/new/models/ResNET18_CIFAR10_UN_{n}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11c592",
   "metadata": {},
   "source": [
    "___\n",
    "## Evaluate multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee59dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tarfile\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Firstly, all the data\n",
    "class SubData(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "\n",
    "        img = Image.open(f\"{path}\").convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        label = torch.tensor(label)\n",
    "        return img.to(self.device), label.to(self.device)\n",
    "\n",
    "data_dir = f'data{os.sep}cifar10'\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# classes which are required to un-learn\n",
    "classes_to_forget = [0, 2]\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_train = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_all_ds = ImageFolder(data_dir+f'{os.sep}test', transform_test)\n",
    "valid_all_dl = DataLoader(valid_all_ds, 256,)\n",
    "\n",
    "train_all_ds = ImageFolder(data_dir+f'{os.sep}train', transform_train)\n",
    "train_all_dl = DataLoader(train_all_ds, 256,)\n",
    "\n",
    "rt_tr = {}\n",
    "for t, l in train_all_ds.imgs:\n",
    "    if l not in classes_to_forget:\n",
    "        rt_tr[len(rt_tr)] = (t, l)\n",
    "rt_vl = {}\n",
    "for t, l in valid_all_ds.imgs:\n",
    "    if l not in classes_to_forget:\n",
    "        rt_vl[len(rt_vl)] = (t, l)\n",
    "\n",
    "train_retain_ds = SubData(rt_tr, transform_train)\n",
    "valid_retain_ds = SubData(rt_vl, transform_test)\n",
    "\n",
    "train_retain_dl = DataLoader(train_retain_ds, 256, shuffle=True)\n",
    "valid_retain_dl = DataLoader(valid_retain_ds, 256*2)\n",
    "\n",
    "rt_tr = {}\n",
    "for t, l in train_all_ds.imgs:\n",
    "    if l in classes_to_forget:\n",
    "        rt_tr[len(rt_tr)] = (t, l)\n",
    "rt_vl = {}\n",
    "for t, l in valid_all_ds.imgs:\n",
    "    if l in classes_to_forget:\n",
    "        rt_vl[len(rt_vl)] = (t, l)\n",
    "\n",
    "train_forget_ds = SubData(rt_tr, transform_train)\n",
    "valid_forget_ds = SubData(rt_vl, transform_test)\n",
    "\n",
    "train_forget_dl = DataLoader(train_forget_ds, 256, shuffle=True)\n",
    "valid_forget_dl = DataLoader(train_forget_ds, 256*2)\n",
    "\n",
    "loaders = [\n",
    "    train_all_dl,\n",
    "    valid_all_dl,\n",
    "    train_retain_dl,\n",
    "    valid_retain_dl,\n",
    "    train_forget_dl,\n",
    "    valid_forget_dl,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c37661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.metrics\n",
    "from src.fyemu_tunable import evaluate\n",
    "from torchvision.models import resnet18\n",
    "# mu_ms = load_models_dict()\n",
    "# femu_ms = load_models_dict()\n",
    "\n",
    "exact = resnet18(num_classes = 10).to(DEVICE)\n",
    "exact.load_state_dict(torch.load(\"ResNET18_CIFAR10_RETAIN_CLASSES.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd61db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loaders):\n",
    "    results = []\n",
    "    for loader in loaders:\n",
    "        results.append(evaluate(model, loader))\n",
    "\n",
    "    return results\n",
    "run(exact, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5922b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs_gen = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec23f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_femu = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095208fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Literal\n",
    "\n",
    "def create_boxplots(score_lists: Dict[str, List[float]], title: str = 'Box Plot of Accuracy Scores for Different Models', evaluation: Literal[\"Accuracy\", \"Loss\"] = \"Accuracy\") -> None:\n",
    "    \"\"\"Create a box plot of accuracy scores for each parsed list in the diconary.\"\"\"\n",
    "\n",
    "    # Prepare data for the box plot\n",
    "    data = [scores for scores in score_lists.values()]\n",
    "    labels = list(score_lists.keys())\n",
    "\n",
    "    # Create the box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(data, labels=labels, patch_artist=True)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Subsets')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.ylabel(f'{evaluation} Score')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
